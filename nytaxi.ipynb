{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    # Delimiter lats and lons to NY only\n",
    "    df = df[(-76 <= df['pickup_longitude']) & (df['pickup_longitude'] <= -72)]\n",
    "    df = df[(-76 <= df['dropoff_longitude']) & (df['dropoff_longitude'] <= -72)]\n",
    "    df = df[(38 <= df['pickup_latitude']) & (df['pickup_latitude'] <= 42)]\n",
    "    df = df[(38 <= df['dropoff_latitude']) & (df['dropoff_latitude'] <= 42)]\n",
    "    # Remove possible outliers\n",
    "    df = df[(0 < df['fare_amount']) & (df['fare_amount'] <= 250)]\n",
    "    # Remove inconsistent values\n",
    "    df = df[(df['dropoff_longitude'] != df['pickup_longitude'])]\n",
    "    df = df[(df['dropoff_latitude'] != df['pickup_latitude'])]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def late_night (row):\n",
    "    if (row['hour'] <= 6) or (row['hour'] >= 20):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def night (row):\n",
    "    if ((row['hour'] <= 20) and (row['hour'] >= 16)) and (row['weekday'] < 5):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "def manhattan(pickup_lat, pickup_long, dropoff_lat, dropoff_long):\n",
    "    return np.abs(dropoff_lat - pickup_lat) + np.abs(dropoff_long - pickup_long)\n",
    "\n",
    "\n",
    "def add_time_features(df):\n",
    "    df['pickup_datetime'] =  pd.to_datetime(df['pickup_datetime'], format='%Y-%m-%d %H:%M:%S %Z')\n",
    "    df['year'] = df['pickup_datetime'].apply(lambda x: x.year)\n",
    "    df['month'] = df['pickup_datetime'].apply(lambda x: x.month)\n",
    "    df['day'] = df['pickup_datetime'].apply(lambda x: x.day)\n",
    "    df['hour'] = df['pickup_datetime'].apply(lambda x: x.hour)\n",
    "    df['weekday'] = df['pickup_datetime'].apply(lambda x: x.weekday())\n",
    "    df['pickup_datetime'] =  df['pickup_datetime'].apply(lambda x: str(x))\n",
    "    df['night'] = df.apply (lambda x: night(x), axis=1)\n",
    "    df['late_night'] = df.apply (lambda x: late_night(x), axis=1)\n",
    "    # Drop 'pickup_datetime' as we won't need it anymore\n",
    "    df = df.drop('pickup_datetime', axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_coordinate_features(df):\n",
    "    lat1 = df['pickup_latitude']\n",
    "    lat2 = df['dropoff_latitude']\n",
    "    lon1 = df['pickup_longitude']\n",
    "    lon2 = df['dropoff_longitude']\n",
    "    \n",
    "    # Add new features\n",
    "    df['latdiff'] = (lat1 - lat2)\n",
    "    df['londiff'] = (lon1 - lon2)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_distances_features(df):\n",
    "    # Add distances from airpot and downtown\n",
    "    ny = (-74.0063889, 40.7141667)\n",
    "    jfk = (-73.7822222222, 40.6441666667)\n",
    "    ewr = (-74.175, 40.69)\n",
    "    lgr = (-73.87, 40.77)\n",
    "    \n",
    "    lat1 = df['pickup_latitude']\n",
    "    lat2 = df['dropoff_latitude']\n",
    "    lon1 = df['pickup_longitude']\n",
    "    lon2 = df['dropoff_longitude']\n",
    "    \n",
    "    df['euclidean'] = (df['latdiff'] ** 2 + df['londiff'] ** 2) ** 0.5\n",
    "    df['manhattan'] = manhattan(lat1, lon1, lat2, lon2)\n",
    "    \n",
    "    df['downtown_pickup_distance'] = manhattan(ny[1], ny[0], lat1, lon1)\n",
    "    df['downtown_dropoff_distance'] = manhattan(ny[1], ny[0], lat2, lon2)\n",
    "    df['jfk_pickup_distance'] = manhattan(jfk[1], jfk[0], lat1, lon1)\n",
    "    df['jfk_dropoff_distance'] = manhattan(jfk[1], jfk[0], lat2, lon2)\n",
    "    df['ewr_pickup_distance'] = manhattan(ewr[1], ewr[0], lat1, lon1)\n",
    "    df['ewr_dropoff_distance'] = manhattan(ewr[1], ewr[0], lat2, lon2)\n",
    "    df['lgr_pickup_distance'] = manhattan(lgr[1], lgr[0], lat1, lon1)\n",
    "    df['lgr_dropoff_distance'] = manhattan(lgr[1], lgr[0], lat2, lon2)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_submission(raw_test, prediction, id_column, prediction_column, file_name):\n",
    "    df = pd.DataFrame(prediction, columns=[prediction_column])\n",
    "    df[id_column] = raw_test[id_column]\n",
    "    df[[id_column, prediction_column]].to_csv((file_name), index=False)\n",
    "    print('Output complete')\n",
    "    \n",
    "    \n",
    "def plot_loss_accuracy(history):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'train.csv'\n",
    "TEST_PATH = 'test.csv'\n",
    "SUBMISSION_NAME = 'submission.csv'\n",
    "\n",
    "# Model parameters\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "DATASET_SIZE = 6000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load values in a more compact form\n",
    "datatypes = {'key': 'str', \n",
    "              'fare_amount': 'float32',\n",
    "              'pickup_datetime': 'str', \n",
    "              'pickup_longitude': 'float32',\n",
    "              'pickup_latitude': 'float32',\n",
    "              'dropoff_longitude': 'float32',\n",
    "              'dropoff_latitude': 'float32',\n",
    "              'passenger_count': 'uint8'}\n",
    "\n",
    "# Only a fraction of the whole data\n",
    "train = pd.read_csv(TRAIN_PATH, nrows=DATASET_SIZE, dtype=datatypes, usecols=[1,2,3,4,5,6])\n",
    "test = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>manhattan</th>\n",
       "      <th>downtown_pickup_distance</th>\n",
       "      <th>downtown_dropoff_distance</th>\n",
       "      <th>jfk_pickup_distance</th>\n",
       "      <th>jfk_dropoff_distance</th>\n",
       "      <th>ewr_pickup_distance</th>\n",
       "      <th>ewr_dropoff_distance</th>\n",
       "      <th>lgr_pickup_distance</th>\n",
       "      <th>lgr_dropoff_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>-73.844315</td>\n",
       "      <td>40.721317</td>\n",
       "      <td>-73.841614</td>\n",
       "      <td>40.712276</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009436</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>0.169225</td>\n",
       "      <td>0.166665</td>\n",
       "      <td>0.139243</td>\n",
       "      <td>0.127501</td>\n",
       "      <td>0.362003</td>\n",
       "      <td>0.355663</td>\n",
       "      <td>0.074368</td>\n",
       "      <td>0.086110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.9</td>\n",
       "      <td>-74.016045</td>\n",
       "      <td>40.711304</td>\n",
       "      <td>-73.979271</td>\n",
       "      <td>40.782005</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079693</td>\n",
       "      <td>0.107475</td>\n",
       "      <td>0.012519</td>\n",
       "      <td>0.094957</td>\n",
       "      <td>0.300959</td>\n",
       "      <td>0.334887</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.287734</td>\n",
       "      <td>0.204741</td>\n",
       "      <td>0.121276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>-73.982735</td>\n",
       "      <td>40.761269</td>\n",
       "      <td>-73.991241</td>\n",
       "      <td>40.750561</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013676</td>\n",
       "      <td>0.019215</td>\n",
       "      <td>0.070756</td>\n",
       "      <td>0.051542</td>\n",
       "      <td>0.317614</td>\n",
       "      <td>0.315413</td>\n",
       "      <td>0.263534</td>\n",
       "      <td>0.244319</td>\n",
       "      <td>0.121466</td>\n",
       "      <td>0.140681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.7</td>\n",
       "      <td>-73.987129</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991570</td>\n",
       "      <td>40.758091</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025340</td>\n",
       "      <td>0.029388</td>\n",
       "      <td>0.038236</td>\n",
       "      <td>0.058744</td>\n",
       "      <td>0.293883</td>\n",
       "      <td>0.323272</td>\n",
       "      <td>0.231014</td>\n",
       "      <td>0.251521</td>\n",
       "      <td>0.153986</td>\n",
       "      <td>0.133479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.3</td>\n",
       "      <td>-73.968094</td>\n",
       "      <td>40.768009</td>\n",
       "      <td>-73.956657</td>\n",
       "      <td>40.783764</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019468</td>\n",
       "      <td>0.027191</td>\n",
       "      <td>0.092138</td>\n",
       "      <td>0.119329</td>\n",
       "      <td>0.309714</td>\n",
       "      <td>0.314032</td>\n",
       "      <td>0.284915</td>\n",
       "      <td>0.312106</td>\n",
       "      <td>0.100085</td>\n",
       "      <td>0.100421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0          4.5        -73.844315        40.721317         -73.841614   \n",
       "1         16.9        -74.016045        40.711304         -73.979271   \n",
       "2          5.7        -73.982735        40.761269         -73.991241   \n",
       "3          7.7        -73.987129        40.733143         -73.991570   \n",
       "4          5.3        -73.968094        40.768009         -73.956657   \n",
       "\n",
       "   dropoff_latitude  year  month  day  hour  weekday          ...           \\\n",
       "0         40.712276  2009      6   15    17        0          ...            \n",
       "1         40.782005  2010      1    5    16        1          ...            \n",
       "2         40.750561  2011      8   18     0        3          ...            \n",
       "3         40.758091  2012      4   21     4        5          ...            \n",
       "4         40.783764  2010      3    9     7        1          ...            \n",
       "\n",
       "   euclidean  manhattan  downtown_pickup_distance  downtown_dropoff_distance  \\\n",
       "0   0.009436   0.011742                  0.169225                   0.166665   \n",
       "1   0.079693   0.107475                  0.012519                   0.094957   \n",
       "2   0.013676   0.019215                  0.070756                   0.051542   \n",
       "3   0.025340   0.029388                  0.038236                   0.058744   \n",
       "4   0.019468   0.027191                  0.092138                   0.119329   \n",
       "\n",
       "   jfk_pickup_distance  jfk_dropoff_distance  ewr_pickup_distance  \\\n",
       "0             0.139243              0.127501             0.362003   \n",
       "1             0.300959              0.334887             0.180259   \n",
       "2             0.317614              0.315413             0.263534   \n",
       "3             0.293883              0.323272             0.231014   \n",
       "4             0.309714              0.314032             0.284915   \n",
       "\n",
       "   ewr_dropoff_distance  lgr_pickup_distance  lgr_dropoff_distance  \n",
       "0              0.355663             0.074368              0.086110  \n",
       "1              0.287734             0.204741              0.121276  \n",
       "2              0.244319             0.121466              0.140681  \n",
       "3              0.251521             0.153986              0.133479  \n",
       "4              0.312106             0.100085              0.100421  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "train = clean(train)\n",
    "\n",
    "train = add_time_features(train)\n",
    "test = add_time_features(test)\n",
    "\n",
    "add_coordinate_features(train)\n",
    "add_coordinate_features(test)\n",
    "\n",
    "train = add_distances_features(train)\n",
    "test = add_distances_features(test)\n",
    "\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>night</th>\n",
       "      <th>late_night</th>\n",
       "      <th>latdiff</th>\n",
       "      <th>londiff</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>manhattan</th>\n",
       "      <th>downtown_pickup_distance</th>\n",
       "      <th>downtown_dropoff_distance</th>\n",
       "      <th>jfk_pickup_distance</th>\n",
       "      <th>jfk_dropoff_distance</th>\n",
       "      <th>ewr_pickup_distance</th>\n",
       "      <th>ewr_dropoff_distance</th>\n",
       "      <th>lgr_pickup_distance</th>\n",
       "      <th>lgr_dropoff_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009041</td>\n",
       "      <td>-0.002701</td>\n",
       "      <td>0.009436</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>0.169225</td>\n",
       "      <td>0.166665</td>\n",
       "      <td>0.139243</td>\n",
       "      <td>0.127501</td>\n",
       "      <td>0.362003</td>\n",
       "      <td>0.355663</td>\n",
       "      <td>0.074368</td>\n",
       "      <td>0.086110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.9</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.070702</td>\n",
       "      <td>-0.036774</td>\n",
       "      <td>0.079693</td>\n",
       "      <td>0.107475</td>\n",
       "      <td>0.012519</td>\n",
       "      <td>0.094957</td>\n",
       "      <td>0.300959</td>\n",
       "      <td>0.334887</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.287734</td>\n",
       "      <td>0.204741</td>\n",
       "      <td>0.121276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010708</td>\n",
       "      <td>0.008507</td>\n",
       "      <td>0.013676</td>\n",
       "      <td>0.019215</td>\n",
       "      <td>0.070756</td>\n",
       "      <td>0.051542</td>\n",
       "      <td>0.317614</td>\n",
       "      <td>0.315413</td>\n",
       "      <td>0.263534</td>\n",
       "      <td>0.244319</td>\n",
       "      <td>0.121466</td>\n",
       "      <td>0.140681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.024948</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.025340</td>\n",
       "      <td>0.029388</td>\n",
       "      <td>0.038236</td>\n",
       "      <td>0.058744</td>\n",
       "      <td>0.293883</td>\n",
       "      <td>0.323272</td>\n",
       "      <td>0.231014</td>\n",
       "      <td>0.251521</td>\n",
       "      <td>0.153986</td>\n",
       "      <td>0.133479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.3</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.015755</td>\n",
       "      <td>-0.011436</td>\n",
       "      <td>0.019468</td>\n",
       "      <td>0.027191</td>\n",
       "      <td>0.092138</td>\n",
       "      <td>0.119329</td>\n",
       "      <td>0.309714</td>\n",
       "      <td>0.314032</td>\n",
       "      <td>0.284915</td>\n",
       "      <td>0.312106</td>\n",
       "      <td>0.100085</td>\n",
       "      <td>0.100421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount  year  month  day  hour  weekday  night  late_night   latdiff  \\\n",
       "0          4.5  2009      6   15    17        0      1           0  0.009041   \n",
       "1         16.9  2010      1    5    16        1      1           0 -0.070702   \n",
       "2          5.7  2011      8   18     0        3      0           1  0.010708   \n",
       "3          7.7  2012      4   21     4        5      0           1 -0.024948   \n",
       "4          5.3  2010      3    9     7        1      0           0 -0.015755   \n",
       "\n",
       "    londiff  euclidean  manhattan  downtown_pickup_distance  \\\n",
       "0 -0.002701   0.009436   0.011742                  0.169225   \n",
       "1 -0.036774   0.079693   0.107475                  0.012519   \n",
       "2  0.008507   0.013676   0.019215                  0.070756   \n",
       "3  0.004440   0.025340   0.029388                  0.038236   \n",
       "4 -0.011436   0.019468   0.027191                  0.092138   \n",
       "\n",
       "   downtown_dropoff_distance  jfk_pickup_distance  jfk_dropoff_distance  \\\n",
       "0                   0.166665             0.139243              0.127501   \n",
       "1                   0.094957             0.300959              0.334887   \n",
       "2                   0.051542             0.317614              0.315413   \n",
       "3                   0.058744             0.293883              0.323272   \n",
       "4                   0.119329             0.309714              0.314032   \n",
       "\n",
       "   ewr_pickup_distance  ewr_dropoff_distance  lgr_pickup_distance  \\\n",
       "0             0.362003              0.355663             0.074368   \n",
       "1             0.180259              0.287734             0.204741   \n",
       "2             0.263534              0.244319             0.121466   \n",
       "3             0.231014              0.251521             0.153986   \n",
       "4             0.284915              0.312106             0.100085   \n",
       "\n",
       "   lgr_dropoff_distance  \n",
       "0              0.086110  \n",
       "1              0.121276  \n",
       "2              0.140681  \n",
       "3              0.133479  \n",
       "4              0.100421  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unwanted columns\n",
    "dropped_columns = ['pickup_longitude', 'pickup_latitude', \n",
    "                   'dropoff_longitude', 'dropoff_latitude']\n",
    "train_clean = train.drop(dropped_columns, axis=1)\n",
    "test_clean = test.drop(dropped_columns + ['key', 'passenger_count'], axis=1)\n",
    "\n",
    "# peek data\n",
    "train_clean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tty/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_df, validation_df = train_test_split(train_clean, test_size=0.10, random_state=1)\n",
    "\n",
    "# Get labels\n",
    "train_labels = train_df['fare_amount'].values\n",
    "validation_labels = validation_df['fare_amount'].values\n",
    "train_df = train_df.drop(['fare_amount'], axis=1)\n",
    "validation_df = validation_df.drop(['fare_amount'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# Scale data\n",
    "# Note: im doing this here with sklearn scaler but, on the Coursera code the scaling is done with Dataflow and Tensorflow\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "train_df_scaled = scaler.fit_transform(train_df)\n",
    "validation_df_scaled = scaler.transform(validation_df)\n",
    "test_scaled = scaler.transform(test_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=train_df_scaled.shape[1], activity_regularizer=regularizers.l1(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1))\n",
    "\n",
    "adam = optimizers.adam(lr=LEARNING_RATE)\n",
    "model.compile(loss='mse', optimizer=adam, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 256)               5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 50,577\n",
      "Trainable params: 49,601\n",
      "Non-trainable params: 976\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5225686 samples, validate on 580632 samples\n",
      "Epoch 1/50\n",
      "5225686/5225686 [==============================] - 429s 82us/step - loss: 19.2900 - mean_absolute_error: 2.2595 - val_loss: 30.0279 - val_mean_absolute_error: 1.9857\n",
      "Epoch 2/50\n",
      "2415104/5225686 [============>.................] - ETA: 9:08 - loss: 15.6460 - mean_absolute_error: 1.9886"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-2737004f2721>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(x=train_df_scaled, y=train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS, \n\u001b[1;32m      2\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_df_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                     shuffle=True)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_df_scaled, y=train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "                    verbose=1, validation_data=(validation_df_scaled, validation_labels), \n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "prediction = model.predict(test_scaled, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output prediction\n",
    "output_submission(test, prediction, 'key', 'fare_amount', SUBMISSION_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
